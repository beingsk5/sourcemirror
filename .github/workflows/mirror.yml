name: Public SourceForge Mirror

on:
  workflow_dispatch:
    inputs:
      job_id:
        required: true
        type: string
      urls:
        required: false
        type: string
      links:
        required: false
        type: string
      notes:
        required: false
        type: string
      retry_files:
        required: false
        type: string
      compression:
        required: false
        type: string

permissions:
  contents: write

jobs:
  mirror:
    runs-on: ubuntu-latest

    steps:

      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # --------------------------------------------------
      # prepare progress branch (DO NOT CHANGE PATHING)
      # --------------------------------------------------
      - name: Prepare progress branch
        run: |
          git config user.name "progress-bot"
          git config user.email "progress@bot"

          git fetch origin

          if git show-ref --verify --quiet refs/remotes/origin/progress; then
            git checkout progress
            git pull origin progress
          else
            git checkout --orphan progress
            git rm -rf .
            mkdir -p progress
            git add progress
            git commit -m "init progress branch"
            git push origin progress
          fi

      # --------------------------------------------------
      # record job start time
      # --------------------------------------------------
      - name: Record job start time
        run: |
          mkdir -p work
          date -u +%s > work/start_time.txt

      # --------------------------------------------------
      # build working file list  (FIX rename/ext + auto folder)
      # --------------------------------------------------
      - name: Build job file list
        run: |
          mkdir -p work

          python3 << 'EOF'
          import json, os, pathlib

          links = os.environ.get("LINKS")
          urls  = os.environ.get("URLS")
          retry = os.environ.get("RETRY")
          compression_raw = os.environ.get("COMPRESSION")

          compression = None
          if compression_raw:
              try:
                  compression = json.loads(compression_raw)
              except:
                  compression = None

          def archive_ext(t):
              return {
                  "zip": "zip",
                  "7z": "7z",
                  "tar.gz": "tar.gz",
                  "tar.bz2": "tar.bz2",
                  "tar.xz": "tar.xz",
                  "gz": "gz",
                  "bz2": "bz2",
                  "xz": "xz"
              }.get(t, "zip")

          files = []

          if retry:
              try:
                  arr = json.loads(retry)
              except:
                  arr = []

              for f in arr:
                  files.append({
                      "url": "",
                      "original": f,
                      "final": f,
                      "folder": "",
                      "notes": "",
                      "status": "retry"
                  })

          elif links:
              try:
                  arr = json.loads(links)
              except:
                  arr = []

              for x in arr:
                  url = x.get("url","")
                  name = url.split("/")[-1] or "file"

                  base   = x.get("rename_base") or ""
                  folder = (x.get("folder") or "").strip()
                  notes  = x.get("notes") or ""
                  rename = x.get("rename") or ""

                  orig_ext = pathlib.Path(name).suffix
                  orig_stem = pathlib.Path(name).stem

                  if not folder:
                      folder = orig_stem

                  if compression and compression.get("enabled"):
                      final = os.environ["JOB_ID"] + "." + archive_ext(compression.get("type","zip"))
                  else:
                      if rename:
                          p = pathlib.Path(rename)
                          if p.suffix:
                              final = rename
                          else:
                              final = rename + orig_ext
                      elif base:
                          final = base + orig_ext
                      else:
                          final = name

                  files.append({
                      "url": url,
                      "original": name,
                      "final": final,
                      "folder": folder,
                      "notes": notes,
                      "status": "pending"
                  })

          elif urls:
              for u in urls.splitlines():
                  u = u.strip()
                  if not u:
                      continue

                  name = u.split("/")[-1] or "file"
                  stem = pathlib.Path(name).stem

                  files.append({
                      "url": u,
                      "original": name,
                      "final": name,
                      "folder": stem,
                      "notes": "",
                      "status": "pending"
                  })

          with open("work/files.json","w") as f:
              json.dump({
                  "compression": compression,
                  "files": files
              }, f, indent=2)

          EOF
        env:
          LINKS: ${{ inputs.links }}
          URLS:  ${{ inputs.urls }}
          RETRY: ${{ inputs.retry_files }}
          COMPRESSION: ${{ inputs.compression }}
          JOB_ID: ${{ inputs.job_id }}

      # -----------------------------
      # validating
      # -----------------------------
      - name: Stage – validating
        run: |
          mkdir -p progress
          echo "validating" > progress/${{ inputs.job_id }}.txt
          git add progress/${{ inputs.job_id }}.txt
          git commit -m "stage validating ${{ inputs.job_id }}" || true
          git push origin progress

      # -----------------------------
      # downloading
      # -----------------------------
      - name: Stage – downloading
        run: |
          echo "downloading" > progress/${{ inputs.job_id }}.txt
          git add progress/${{ inputs.job_id }}.txt
          git commit -m "stage downloading ${{ inputs.job_id }}" || true
          git push origin progress

          sudo apt-get update -y
          sudo apt-get install -y aria2 p7zip-full zip

          mkdir -p work/upload

          python3 << 'EOF'
          import json, pathlib, subprocess

          with open("work/files.json") as f:
              data = json.load(f)

          for fobj in data["files"]:
              urls = fobj.get("url")
              if not urls:
                  continue

              if isinstance(urls, str):
                  url_list = [urls]
              elif isinstance(urls, list):
                  url_list = urls
              else:
                  continue

              folder = fobj.get("folder","").strip("/")
              name   = fobj.get("original")

              outdir = pathlib.Path("work/upload") / folder
              outdir.mkdir(parents=True, exist_ok=True)

              base = [
                  "aria2c",
                  "--file-allocation=trunc",
                  "--auto-file-renaming=false",
                  "--summary-interval=0",
                  "-k","1M",
                  "-o", name,
                  "-d", str(outdir)
              ]

              fast = base + ["-x","8","-s","8"] + url_list

              r = subprocess.run(fast)

              if r.returncode != 0:
                  slow = base + ["-x","1","-s","1"] + url_list
                  subprocess.run(slow)

          EOF

      # -----------------------------
      # apply final filenames
      # -----------------------------
      - name: Apply final filenames
        run: |
          python3 << 'EOF'
          import json, pathlib, shutil

          with open("work/files.json") as f:
              data = json.load(f)

          compression = data.get("compression")

          if compression and compression.get("enabled"):
              exit(0)

          root = pathlib.Path("work/upload")

          for fobj in data["files"]:
              folder = fobj.get("folder","").strip("/")
              src = root / folder / fobj["original"]
              dst = root / folder / fobj["final"]

              if src.exists() and src != dst:
                  dst.parent.mkdir(parents=True, exist_ok=True)
                  if dst.exists():
                      dst.unlink()
                  shutil.move(src, dst)

          EOF

      # -----------------------------
      # compression (ONE ARCHIVE PER JOB)
      # -----------------------------
      - name: Build archive (if enabled)
        run: |
          python3 << 'EOF'
          import json, os, subprocess, pathlib, shutil

          with open("work/files.json") as f:
              data = json.load(f)

          comp = data.get("compression")

          if not (comp and comp.get("enabled")):
              exit(0)

          job = os.environ["JOB_ID"]
          t = comp.get("type","zip")

          src = pathlib.Path("work/upload")
          out = pathlib.Path("work/archive")
          out.mkdir(parents=True, exist_ok=True)

          archive = out / job

          if t == "zip":
              subprocess.check_call(["zip","-r",f"{archive}.zip","."], cwd=src)
              final = archive.with_suffix(".zip")

          elif t == "7z":
              subprocess.check_call(["7z","a",f"{archive}.7z","."], cwd=src)
              final = archive.with_suffix(".7z")

          else:
              name = f"{archive}.{t}"
              subprocess.check_call(["tar","-cavf",name,"."], cwd=src)
              final = pathlib.Path(name)

          shutil.rmtree(src)
          src.mkdir(parents=True, exist_ok=True)
          shutil.move(str(final), src / final.name)

          EOF
        env:
          JOB_ID: ${{ inputs.job_id }}

      # -----------------------------
      # uploading
      # -----------------------------
      - name: Stage – uploading
        run: |
          echo "uploading" > progress/${{ inputs.job_id }}.txt
          git add progress/${{ inputs.job_id }}.txt
          git commit -m "stage uploading ${{ inputs.job_id }}" || true
          git push origin progress

          mkdir -p ~/.ssh
          echo "${{ secrets.SF_SSHKEY }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          ssh-keyscan frs.sourceforge.net >> ~/.ssh/known_hosts

          rsync -av --partial \
            work/upload/ \
            ${{ secrets.SF_USER }}@frs.sourceforge.net:/home/frs/project/${{ secrets.SF_PROJECT }}/

      # -----------------------------
      # verifying
      # -----------------------------
      - name: Stage – verifying
        run: |
          echo "verifying" > progress/${{ inputs.job_id }}.txt
          git add progress/${{ inputs.job_id }}.txt
          git commit -m "stage verifying ${{ inputs.job_id }}" || true
          git push origin progress

      # --------------------------------------------------
      # result + summary (REMOTE SSH VERIFICATION + UI FIELDS)
      # --------------------------------------------------
      - name: Build result and summary
        run: |
          mkdir -p progress/result

          python3 << 'EOF'
          import json, time, os, subprocess

          with open("work/start_time.txt") as f:
              start = int(f.read().strip())

          with open("work/files.json") as f:
              data = json.load(f)

          files = data["files"]
          compression = data.get("compression")

          project = os.environ["SF_PROJECT"]
          job_id  = os.environ["JOB_ID"]
          sf_user = os.environ["SF_USER"]

          total = 0

          def rsize(path):
              try:
                  out = subprocess.check_output(
                      ["ssh", f"{sf_user}@frs.sourceforge.net", "stat", "-c", "%s", path],
                      stderr=subprocess.DEVNULL,
                      timeout=20
                  )
                  return int(out.decode().strip())
              except:
                  return None

          def dl(folder, name):
              if folder:
                  return f"https://downloads.sourceforge.net/project/{project}/{folder}/{name}"
              return f"https://downloads.sourceforge.net/project/{project}/{name}"

          if compression and compression.get("enabled"):

              name = os.listdir("work/upload")[0]
              rpath = f"/home/frs/project/{project}/{name}"
              s = rsize(rpath)

              files[:] = [{
                  "job_id": job_id,
                  "original": name,
                  "final": name,
                  "folder": "",
                  "notes": "",
                  "status": "ok" if s is not None else "failed",
                  "size": s or 0,
                  "download": dl("", name)
              }]

              total = s or 0

          else:
              for fobj in files:
                  folder = fobj.get("folder","").strip("/")
                  name   = fobj.get("final")

                  if folder:
                      rpath = f"/home/frs/project/{project}/{folder}/{name}"
                  else:
                      rpath = f"/home/frs/project/{project}/{name}"

                  s = rsize(rpath)

                  if s is not None:
                      fobj["size"] = s
                      fobj["status"] = "ok"
                      total += s
                  else:
                      fobj["size"] = 0
                      if fobj.get("status") != "retry":
                          fobj["status"] = "failed"

                  fobj["download"] = dl(folder, name)
                  fobj["job_id"] = job_id

          now = int(time.time())

          summary = {
              "total_files": len(files),
              "total_bytes": total,
              "time_taken_sec": now - start,
              "total_size": total,
              "time_taken": now - start,
              "started_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(start)),
              "finished_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(now)),
              "compression": compression
          }

          out = {
              "job_id": job_id,
              "files": files,
              "summary": summary,
              "notes": os.environ.get("NOTES","")
          }

          with open(f"progress/result/{job_id}.json","w") as f:
              json.dump(out,f,indent=2)

          EOF
        env:
          SF_PROJECT: ${{ secrets.SF_PROJECT }}
          SF_USER: ${{ secrets.SF_USER }}
          NOTES: ${{ inputs.notes }}
          JOB_ID: ${{ inputs.job_id }}

      - name: Commit result
        run: |
          git add progress/result/${{ inputs.job_id }}.json
          git commit -m "result ${{ inputs.job_id }}" || true
          git push origin progress

      # --------------------------------------------------
      # update mirror history
      # --------------------------------------------------
      - name: Update mirror history
        if: always()
        run: |
          mkdir -p progress

          python3 << 'EOF'
          import json, os, time

          path = "progress/history.json"

          entry = {
              "job_id": os.environ["JOB_ID"],
              "run_id": int(os.environ["RUN_ID"]),
              "status": os.environ.get("CONCLUSION","completed"),
              "time": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
          }

          try:
              with open(path) as f:
                  arr = json.load(f)
                  if not isinstance(arr, list):
                      arr = []
          except:
              arr = []

          arr.insert(0, entry)
          arr = arr[:10]

          with open(path,"w") as f:
              json.dump(arr,f,indent=2)

          EOF

          git add progress/history.json
          git commit -m "history update ${{ inputs.job_id }}" || true
          git push origin progress
        env:
          JOB_ID: ${{ inputs.job_id }}
          RUN_ID: ${{ github.run_id }}
          CONCLUSION: ${{ job.status }}

      # -----------------------------
      # finished
      # -----------------------------
      - name: Stage – finished
        if: always()
        run: |
          echo "finished" > progress/${{ inputs.job_id }}.txt
          git add progress/${{ inputs.job_id }}.txt
          git commit -m "stage finished ${{ inputs.job_id }}" || true
          git push origin progress
